{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q torch transformers accelerate huggingface_hub tqdm matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import re\n",
        "from typing import Dict, List, Tuple\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from huggingface_hub import login\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HF_TOKEN = \"\" \n",
        "\n",
        "if HF_TOKEN:\n",
        "    login(HF_TOKEN)\n",
        "else:\n",
        "    print(\"⚠️ No HF token set. Get one from https://huggingface.co/settings/tokens\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    teacher_model: str = 'meta-llama/Meta-Llama-3-8B'\n",
        "    student_model: str = 'meta-llama/Llama-3.2-1B'\n",
        "    \n",
        "    epochs: int = 80\n",
        "    batch_size: int = 8\n",
        "    learning_rate: float = 1e-4 \n",
        "    lambda_cka: float = 0.05  \n",
        "    grad_clip: float = 1.0\n",
        "    \n",
        "    eval_every: int = 1  \n",
        "\n",
        "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "config = Config()\n",
        "print(f\"Device: {config.device}\")\n",
        "print(f\"Teacher: {config.teacher_model}\")\n",
        "print(f\"Student: {config.student_model}\")\n",
        "print(f\"Learning rate: {config.learning_rate}\")\n",
        "print(f\"Lambda CKA: {config.lambda_cka}\")\n",
        "print(f\"Epochs: {config.epochs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_dataset(filename):\n",
        "    paths = [filename, f\"datasets/{filename}\", f\"Math-Circuit-Distillation-ESE5460/datasets/{filename}\"]\n",
        "    for path in paths:\n",
        "        if os.path.exists(path):\n",
        "            print(f\"✅ Loaded {path}\")\n",
        "            with open(path, 'r') as f:\n",
        "                return json.load(f)\n",
        "    raise FileNotFoundError(f\"Could not find {filename}\")\n",
        "\n",
        "TRAIN_DATA = load_dataset('2d_add_train_80.json')\n",
        "TEST_DATA = load_dataset('2d_add_test_20.json')\n",
        "\n",
        "print(f\"\\nTrain samples: {len(TRAIN_DATA)}\")\n",
        "print(f\"Test samples: {len(TEST_DATA)}\")\n",
        "print(f\"Example: {list(TRAIN_DATA.items())[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def linear_cka(X: torch.Tensor, Y: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
        "    X = X.float()\n",
        "    Y = Y.float()\n",
        "    \n",
        "    if X.dim() == 3:\n",
        "        X = X.reshape(-1, X.size(-1))\n",
        "    if Y.dim() == 3:\n",
        "        Y = Y.reshape(-1, Y.size(-1))\n",
        "    \n",
        "    X = X - X.mean(dim=0, keepdim=True)\n",
        "    Y = Y - Y.mean(dim=0, keepdim=True)\n",
        "    \n",
        "    XtX_norm = torch.norm(X.T @ X, 'fro')\n",
        "    YtY_norm = torch.norm(Y.T @ Y, 'fro')\n",
        "    YtX_norm_sq = torch.norm(Y.T @ X, 'fro') ** 2\n",
        "    \n",
        "    denom = XtX_norm * YtY_norm + eps\n",
        "    if denom < eps:\n",
        "        return torch.tensor(0.0, device=X.device, dtype=torch.float32)\n",
        "    \n",
        "    cka = YtX_norm_sq / denom\n",
        "    return torch.clamp(cka, 0.0, 1.0)\n",
        "\n",
        "\n",
        "class CKALoss(nn.Module):\n",
        "    def forward(self, student_acts: torch.Tensor, teacher_acts: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        cka = linear_cka(student_acts, teacher_acts)\n",
        "        loss = 1.0 - cka\n",
        "        return loss, cka\n",
        "\n",
        "X = torch.randn(32, 128)\n",
        "print(f\"CKA(X, X) = {linear_cka(X, X).item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ABLATION_SCORES = {\n",
        "    \"delta_s\": {0: 0.4297, 1: 0.4297, 2: -0.1641, 3: -0.0391, 4: 0.1406, 5: 0.1641, \n",
        "                6: 0.0156, 7: 0.0781, 8: 0.375, 9: 0.375, 10: 0.3828, 11: 0.3203, \n",
        "                12: 0.3281, 13: 0.2812, 14: 0.4297, 15: 0.4297},\n",
        "    \"delta_t\": {0: 0.9453, 1: 0.9453, 2: 0.1328, 3: 0.0, 4: 0.0391, 5: 0.1094, \n",
        "                6: -0.0234, 7: -0.0234, 8: -0.0078, 9: 0.0547, 10: 0.0078, 11: 0.0, \n",
        "                12: 0.1797, 13: 0.0469, 14: 0.3828, 15: 0.7734, 16: 0.1953, 17: 0.1406, \n",
        "                18: 0.7188, 19: 0.1797, 20: 0.0234, 21: -0.0078, 22: 0.0312, 23: 0.0469, \n",
        "                24: 0.0625, 25: 0.0156, 26: 0.0, 27: 0.0312, 28: -0.0078, 29: 0.0, \n",
        "                30: 0.0, 31: 0.2188}\n",
        "}\n",
        "\n",
        "def create_layer_mapping(delta_s: Dict, delta_t: Dict, top_k: int = 8) -> Dict[int, int]:\n",
        "    max_s = max(abs(v) for v in delta_s.values()) or 1.0\n",
        "    max_t = max(abs(v) for v in delta_t.values()) or 1.0\n",
        "    delta_s_norm = {k: v / max_s for k, v in delta_s.items()}\n",
        "    delta_t_norm = {k: v / max_t for k, v in delta_t.items()}\n",
        "    \n",
        "    sorted_s = sorted(delta_s_norm.items(), key=lambda x: abs(x[1]), reverse=True)[:top_k]\n",
        "    \n",
        "    mapping = {}\n",
        "    for s_idx, s_score in sorted_s:\n",
        "        best_t = min(delta_t_norm.keys(), key=lambda t: abs(s_score - delta_t_norm[t]))\n",
        "        mapping[s_idx] = best_t\n",
        "    \n",
        "    return mapping\n",
        "\n",
        "LAYER_MAPPING = create_layer_mapping(ABLATION_SCORES['delta_s'], ABLATION_SCORES['delta_t'], top_k=8)\n",
        "print(f\"Layer mapping (top 8 by importance):\")\n",
        "for s, t in sorted(LAYER_MAPPING.items()):\n",
        "    print(f\"  Student layer {s} -> Teacher layer {t}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AddDataset(Dataset):\n",
        "    \"\"\"Dataset matching friend's implementation - no padding.\"\"\"\n",
        "    def __init__(self, json_data: Dict, tokenizer):\n",
        "        self.data = list(json_data.items())\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        prompt, answer = self.data[idx]\n",
        "        answer = str(answer)\n",
        "        \n",
        "        prompt_ids = self.tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=False,\n",
        "        )[\"input_ids\"].squeeze(0)\n",
        "\n",
        "        answer_ids = self.tokenizer(\n",
        "            answer + self.tokenizer.eos_token,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=False,\n",
        "        )[\"input_ids\"].squeeze(0)\n",
        "        \n",
        "        input_ids = torch.cat([prompt_ids, answer_ids])\n",
        "        attention_mask = torch.ones_like(input_ids)\n",
        "        \n",
        "        labels = torch.full_like(input_ids, -100)\n",
        "        labels[len(prompt_ids):] = answer_ids\n",
        "        \n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": labels,\n",
        "            \"prompt_len\": len(prompt_ids),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ActivationCache:\n",
        "    def __init__(self):\n",
        "        self.activations = {}\n",
        "        self.hooks = []\n",
        "    \n",
        "    def _make_hook(self, layer_idx):\n",
        "        def hook(module, input, output):\n",
        "            self.activations[layer_idx] = output\n",
        "        return hook\n",
        "    \n",
        "    def register_hooks(self, model, layer_indices: List[int]):\n",
        "        self.clear()\n",
        "        for idx in layer_indices:\n",
        "            hook = model.model.layers[idx].mlp.register_forward_hook(self._make_hook(idx))\n",
        "            self.hooks.append(hook)\n",
        "    \n",
        "    def clear(self):\n",
        "        self.activations = {}\n",
        "        for h in self.hooks:\n",
        "            h.remove()\n",
        "        self.hooks = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Evaluation Function (Matching Friend's)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_int_after_equals(text):\n",
        "    m = re.search(r\"=\\s*(\\d+)\", text)\n",
        "    return int(m.group(1)) if m else None\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_accuracy(model, tokenizer, data: Dict, batch_size=50) -> float:\n",
        "    model.eval()\n",
        "    \n",
        "    prompts = list(data.keys())\n",
        "    answers = list(data.values())\n",
        "    \n",
        "    correct, total = 0, 0\n",
        "    original_padding_side = tokenizer.padding_side\n",
        "    tokenizer.padding_side = \"right\" \n",
        "    \n",
        "    for i in tqdm(range(0, len(prompts), batch_size), desc=\"Evaluating\", leave=False):\n",
        "        batch_prompts = prompts[i:i + batch_size]\n",
        "        batch_answers = answers[i:i + batch_size]\n",
        "        \n",
        "        inputs = tokenizer(\n",
        "            batch_prompts,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "        ).to(model.device)\n",
        "        \n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=10,\n",
        "            do_sample=False,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "        \n",
        "        decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "        \n",
        "        for pred, gold in zip(decoded, batch_answers):\n",
        "            pred_ans = extract_int_after_equals(pred)\n",
        "            if pred_ans == gold:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "    \n",
        "    tokenizer.padding_side = original_padding_side\n",
        "    return correct / max(total, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = config.device\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.student_model)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(f\"Loading student model: {config.student_model}\")\n",
        "student = AutoModelForCausalLM.from_pretrained(\n",
        "    config.student_model,\n",
        "    torch_dtype=torch.float32,  \n",
        "    device_map=device\n",
        ")\n",
        "\n",
        "print(f\"Loading teacher model: {config.teacher_model}\")\n",
        "teacher = AutoModelForCausalLM.from_pretrained(\n",
        "    config.teacher_model,\n",
        "    torch_dtype=torch.float32,\n",
        "    device_map=device\n",
        ")\n",
        "teacher.eval()\n",
        "for p in teacher.parameters():\n",
        "    p.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*50)\n",
        "print(\"BASELINE EVALUATION (before training)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "baseline_student = eval_accuracy(student, tokenizer, TEST_DATA)\n",
        "print(f\"Student (1B) baseline accuracy: {baseline_student:.3f}\")\n",
        "\n",
        "baseline_teacher = eval_accuracy(teacher, tokenizer, TEST_DATA)\n",
        "print(f\"Teacher (8B) baseline accuracy: {baseline_teacher:.3f}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = AddDataset(TRAIN_DATA, tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
        "\n",
        "optimizer = AdamW(student.parameters(), lr=config.learning_rate)\n",
        "cka_loss_fn = CKALoss()\n",
        "\n",
        "student_layers = list(LAYER_MAPPING.keys())\n",
        "teacher_layers = list(set(LAYER_MAPPING.values()))\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Batches per epoch: {len(train_loader)}\")\n",
        "print(f\"Student layers for CKA: {student_layers}\")\n",
        "print(f\"Teacher layers for CKA: {teacher_layers}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = {\n",
        "    'epoch': [],\n",
        "    'ce_loss': [],\n",
        "    'cka_loss': [],\n",
        "    'total_loss': [],\n",
        "    'accuracy': [],\n",
        "}\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Starting training for {config.epochs} epochs\")\n",
        "print(f\"Learning Rate: {config.learning_rate}\")\n",
        "print(f\"Lambda CKA: {config.lambda_cka}\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "best_accuracy = baseline_student\n",
        "\n",
        "for epoch in range(config.epochs):\n",
        "    student.train()\n",
        "    epoch_ce, epoch_cka, epoch_total = 0, 0, 0\n",
        "    n_batches = 0\n",
        "    \n",
        "    student_cache = ActivationCache()\n",
        "    teacher_cache = ActivationCache()\n",
        "    \n",
        "    for step, batch in enumerate(train_loader):\n",
        "        batch = {\n",
        "            k: (v.to(device) if torch.is_tensor(v) else v)\n",
        "            for k, v in batch.items()\n",
        "        }\n",
        "        \n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['labels']\n",
        "        \n",
        "        if (labels != -100).sum().item() == 0:\n",
        "            continue\n",
        "        \n",
        "        student_cache.register_hooks(student, student_layers)\n",
        "        teacher_cache.register_hooks(teacher, teacher_layers)\n",
        "        \n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                teacher(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            t_acts = {k: v.detach() for k, v in teacher_cache.activations.items()}\n",
        "            \n",
        "            outputs = student(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels,\n",
        "            )\n",
        "            s_acts = student_cache.activations\n",
        "            \n",
        "            ce_loss = outputs.loss\n",
        "            \n",
        "            cka_losses = []\n",
        "            for s_idx, t_idx in LAYER_MAPPING.items():\n",
        "                if s_idx in s_acts and t_idx in t_acts:\n",
        "                    loss, _ = cka_loss_fn(s_acts[s_idx], t_acts[t_idx])\n",
        "                    if not torch.isnan(loss):\n",
        "                        cka_losses.append(loss)\n",
        "            \n",
        "            if cka_losses:\n",
        "                cka_loss = torch.stack(cka_losses).mean()\n",
        "            else:\n",
        "                cka_loss = torch.tensor(0.0, device=device)\n",
        "            \n",
        "            total_loss = ce_loss + config.lambda_cka * cka_loss\n",
        "            \n",
        "            if torch.isnan(total_loss):\n",
        "                continue\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(student.parameters(), config.grad_clip)\n",
        "            optimizer.step()\n",
        "            \n",
        "            epoch_ce += ce_loss.item()\n",
        "            epoch_cka += cka_loss.item()\n",
        "            epoch_total += total_loss.item()\n",
        "            n_batches += 1\n",
        "            \n",
        "            if step % 50 == 0:\n",
        "                print(f\"  step {step:04d} | CE {ce_loss.item():.4f} | CKA {cka_loss.item():.4f}\")\n",
        "            \n",
        "        finally:\n",
        "            student_cache.clear()\n",
        "            teacher_cache.clear()\n",
        "    \n",
        "    if n_batches > 0:\n",
        "        avg_ce = epoch_ce / n_batches\n",
        "        avg_cka = epoch_cka / n_batches\n",
        "        avg_total = epoch_total / n_batches\n",
        "    else:\n",
        "        avg_ce = avg_cka = avg_total = 0\n",
        "    \n",
        "    accuracy = eval_accuracy(student, tokenizer, TEST_DATA)\n",
        "    \n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        student.save_pretrained('./best_model')\n",
        "        tokenizer.save_pretrained('./best_model')\n",
        "        print(f\"New best model saved!\")\n",
        "    \n",
        "    history['epoch'].append(epoch + 1)\n",
        "    history['ce_loss'].append(avg_ce)\n",
        "    history['cka_loss'].append(avg_cka)\n",
        "    history['total_loss'].append(avg_total)\n",
        "    history['accuracy'].append(accuracy)\n",
        "    \n",
        "    print(f\"\\nEpoch {epoch+1}/{config.epochs}: CE={avg_ce:.4f}, CKA={avg_cka:.4f}, Acc={accuracy:.3f}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Training complete!\")\n",
        "print(f\"Best accuracy: {best_accuracy:.3f} (baseline: {baseline_student:.3f})\")\n",
        "print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FINAL EVALUATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "final_accuracy = eval_accuracy(student, tokenizer, TEST_DATA)\n",
        "print(f\"Final student accuracy: {final_accuracy:.3f}\")\n",
        "print(f\"Baseline was: {baseline_student:.3f}\")\n",
        "print(f\"Improvement: {(final_accuracy - baseline_student)*100:+.2f}%\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "ax1 = axes[0, 0]\n",
        "ax1.plot(history['epoch'], history['total_loss'], 'b-', linewidth=2)\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Total Loss')\n",
        "ax1.set_title('Total Loss (CE + λ*CKA)')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "ax2 = axes[0, 1]\n",
        "ax2.plot(history['epoch'], history['ce_loss'], 'b-o', label='CE Loss', markersize=3)\n",
        "ax2.plot(history['epoch'], history['cka_loss'], 'r-o', label='CKA Loss', markersize=3)\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Loss')\n",
        "ax2.set_title('CE and CKA Loss')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "ax3 = axes[1, 0]\n",
        "ax3.plot(history['epoch'], history['accuracy'], 'g-o', markersize=4)\n",
        "ax3.axhline(y=baseline_student, color='gray', linestyle='--', label=f'Baseline ({baseline_student:.3f})')\n",
        "ax3.axhline(y=baseline_teacher, color='blue', linestyle=':', alpha=0.5, label=f'Teacher ({baseline_teacher:.3f})')\n",
        "ax3.set_xlabel('Epoch')\n",
        "ax3.set_ylabel('Accuracy')\n",
        "ax3.set_title('Student Accuracy')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "ax4 = axes[1, 1]\n",
        "improvement = [acc - baseline_student for acc in history['accuracy']]\n",
        "ax4.bar(history['epoch'], improvement, color=['green' if x > 0 else 'red' for x in improvement])\n",
        "ax4.axhline(y=0, color='black', linewidth=0.5)\n",
        "ax4.set_xlabel('Epoch')\n",
        "ax4.set_ylabel('Accuracy Change')\n",
        "ax4.set_title('Accuracy Improvement vs Baseline')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_results.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"\\nSaved: training_results.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_path = \"./circuit_distilled_student\"\n",
        "student.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "\n",
        "results = {\n",
        "    'config': {\n",
        "        'teacher': config.teacher_model,\n",
        "        'student': config.student_model,\n",
        "        'epochs': config.epochs,\n",
        "        'batch_size': config.batch_size,\n",
        "        'learning_rate': config.learning_rate,\n",
        "        'lambda_cka': config.lambda_cka\n",
        "    },\n",
        "    'baseline_student': baseline_student,\n",
        "    'baseline_teacher': baseline_teacher,\n",
        "    'final_accuracy': final_accuracy,\n",
        "    'best_accuracy': best_accuracy,\n",
        "    'history': history\n",
        "}\n",
        "\n",
        "with open(f\"{save_path}/training_results.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(f\"\\nModel saved to: {save_path}\")\n",
        "print(f\"Results saved to: {save_path}/training_results.json\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}

\documentclass[10pt, reqno, letterpaper, twoside]{amsart}
\usepackage[margin=1in]{geometry}

\usepackage{amssymb, bm, mathtools}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage[pdftex, xetex]{graphicx}
\usepackage{enumerate, setspace}
\usepackage{float, colortbl, tabularx, longtable, multirow, subcaption, environ, wrapfig, textcomp, booktabs}
\usepackage{pgf, tikz, framed, url, hyperref}
\usepackage[normalem]{ulem}
\usetikzlibrary{arrows,positioning,automata,shadows,fit,shapes}
\usepackage[english]{babel}

\usepackage{microtype}
\microtypecontext{spacing=nonfrench}

\usepackage{times}
\usepackage[numbers,sort&compress]{natbib}

\title{Circuit Distillation for Math Reasoning: Aligning Computational Mechanisms in Large Language Models}
\author{
Eshan Singhal [esinghal@seas], Audhav Durai [audhav@wharton], \\ Vedant Gaur [vedantg@wharton], Praneel Varshney [pvarsh@seas]
}

\begin{document}

\begin{abstract}
    \emph{Circuit Distillation} is a mechanism-level method for transferring knowledge from a large teacher model to a smaller student model by aligning internal computational circuits rather than matching outputs, as is done in traditional knowledge distillation. We apply this approach to arithmetic reasoning in the Llama~3 family with a novel method that has a two-stage pipeline. First, we discover arithmetic-relevant circuits in the teacher using a classifier-based framework that clusters arithmetic problems into latent classes and learns sparse, mutually distinct, and functionally selective neuron-level masks for each class. Second, we distill these circuits into the student by enforcing mechanism-level alignment through representational similarity objectives. 

    \textbf{[Add 2-3 sentences of results here]}
\end{abstract}

\maketitle

\section{Introduction}

Large language models (LLMs) exhibit strong arithmetic and symbolic reasoning abilities when scaled to tens of billions of parameters \citep{dubey2024llama}. However, deploying such models is often infeasible due to computational and memory constraints. Knowledge distillation aims to address this by transferring capabilities from large teacher models to smaller student models, but conventional approaches focus on matching outputs rather than internal computation. As a result, distilled models often produce correct answers while relying on brittle heuristics rather than the teacher’s underlying algorithmic mechanisms \citep{wadhwa2024mysteries}.

Mechanistic interpretability suggests that many reasoning behaviors in transformers are implemented by sparse, functionally specialized subcircuits composed of particular neurons and attention heads \citep{elhage2021mathematical}. This motivates the question: \emph{can we identify such circuits and distill them directly into smaller models?} If so, student models could inherit not just surface-level behavior but the teacher’s internal reasoning process.

In this work, we focus on arithmetic reasoning and propose a neuron-level circuit discovery and distillation framework. We introduce a method that (i) clusters arithmetic problems into latent classes, (ii) learns sparse neuron masks for each class using a structured optimization objective, and (iii) uses these masks as the basis for circuit-level distillation that leverages representational similarity alignment between teacher and student \citep{kornblith2019similarity,williams2025equivalence}. Our approach emphasizes generality. That is, as long as the number of latent classes is sufficiently large to capture meaningful structure, the precise value of this hyperparameter is not critical.

\subsection{Contributions}

\begin{itemize}
\item We propose a neuron-level circuit discovery framework for arithmetic reasoning that jointly clusters problems and learns sparse neuron masks corresponding to each cluster.
\item We introduce a multi-term objective that enforces sparsity, balanced usage, and orthogonality between discovered circuits, yielding interpretable and functionally distinct neuron groups.
\item We apply this framework to both 1B- and 8B-parameter transformer models, demonstrating consistent circuit structure across scales.
\item We outline how the discovered circuits can be integrated into a circuit distillation pipeline for mechanism-level transfer using representational similarity objectives.
\end{itemize}

\section{Background}

\subsection{Transformers and Arithmetic}

Transformers process input sequences through layers of self-attention and feedforward networks (FFNs), producing intermediate activations that can be interpreted as contributing to the model’s computation \citep{elhage2021mathematical}. Arithmetic problems typically consist of fixed-length token sequences (e.g., three tokens for operands and two for operators), yielding structured activation patterns across layers.

\subsection{Neuron Masks as Circuits}

We model a circuit as a \emph{neuron mask}: a vector of weights applied multiplicatively to neuron outputs in FFN layers. This view aligns with research that circuits in transformers can be viewed as sparse subgraphs of the model’s computational graph responsible for particular behaviors \citep{elhage2021mathematical,wadhwa2025circuit}. Learning such masks facilitates both interpretability and targeted interventions.

\subsection{Representational Similarity}

Matching student and teacher representations using metrics invariant to orthogonal transformations, such as Centered Kernel Alignment (CKA), has proven effective for comparing internal states of models with different architectures \citep{kornblith2019similarity,williams2025equivalence}. We leverage this in the distillation objective to align circuit activations across student and teacher.

\section{Related Work}

\textbf{Knowledge Distillation.} Traditional distillation matches teacher and student output distributions and, in some cases, intermediate representations. However, these approaches do not explicitly transfer internal reasoning mechanisms. Chain-of-thought distillation has been proposed to include teacher rationales, but students may imitate style without acquiring causal computation \citep{wadhwa2024mysteries}.

\textbf{Mechanistic Interpretability and Circuits.} Mechanistic interpretability aims to decompose networks into interpretable components such as attention heads and neurons implementing specific functions. The transformer circuits paradigm formalizes this view, identifying subnetworks responsible for tasks like induction and arithmetic reasoning \citep{elhage2021mathematical}. Attribution Patching provides a scalable approximation for estimating component importance \citep{nanda2023attribution,kramar2024atp}.

\textbf{Similarity Metrics.} Centered Kernel Alignment (CKA) has emerged as a robust method for comparing representations across models, due to its invariance to invertible linear transformations and stability in high dimensions \citep{kornblith2019similarity,williams2025equivalence}.

\section{Approach}

Our circuit discovery framework consists of three components: problem encoding and clustering, neuron mask generation, and a multi-term optimization objective that enforces interpretability and functional separation.

\subsection{Problem Encoding and Latent Classes}

Given an arithmetic problem \(x_i\), we compute a fixed-dimensional problem encoding using intermediate transformer activations. This encoding is passed to a \(K\)-class classifier, where \(K\) is a user-specified hyperparameter controlling the granularity of discovered circuits. The classifier’s output distribution is sampled via Gumbel-Softmax with a straight-through estimator to facilitate end-to-end gradients while yielding discrete class assignments.

\subsection{Neuron Mask Generator}

Conditioned on the sampled class, a two-layer feedforward network produces a neuron mask \(\mathbf{m}_k \in (0,1)^D\), where \(D\) is the number of neurons in the target FFN layers. Each mask weight modulates the corresponding neuron activation via elementwise multiplication. Masks are shared across all problems assigned to the same class, encouraging each class to correspond to a consistent computational subcircuit.

\subsection{Objective Function}

We introduce the following notation:

\begin{itemize}
\item \(K\): number of latent problem classes.
\item \(i \in \{1,\dots,N_k\}\): index over problems assigned to class \(k\).
\item \(d \in \{1,\dots,D\}\): neuron index.
\item \(a_{i,k,d}\): activation of neuron \(d\) for problem \(i\) in class \(k\).
\item \(m_{k,d}\): neuron mask weight for neuron \(d\) in class \(k\).
\item \(\mathbf{M}_k \in \mathbb{R}^D\): mask vector for class \(k\).
\item \(f_k\): empirical probability that class \(k\) is selected.
\item \(\pi\): target average mask activation (e.g., \(0.1\)).
\end{itemize}

The total loss is:

\[
\mathcal{L}
= \lambda_1 \mathcal{L}_{\text{sim}}
+ \lambda_2 \mathcal{L}_{\text{usage}}
+ \lambda_3 \mathcal{L}_{\text{sparsity}}
+ \lambda_4 \mathcal{L}_{\text{KL}}
+ \lambda_5 \mathcal{L}_{\text{mask-sim}}.
\]

\subsubsection{Similarity Loss}

\[
\mathcal{L}_{\text{sim}}
= -\frac{1}{K}
\sum_{k=1}^{K}
\frac{1}{N_k (N_k - 1)}
\sum_{d=1}^{D}
\left(
\sum_{i=1}^{N_k} \lVert a_{i,k,d} \rVert
\right)^2.
\]

\subsubsection{Usage Entropy}

\[
\mathcal{L}_{\text{usage}}
= - \sum_{k=1}^{K} f_k \log f_k.
\]

\subsubsection{Sparsity Loss}

\[
\mathcal{L}_{\text{sparsity}}
= -\frac{1}{K}
\sum_{k=1}^{K}
\frac{1}{D}
\sum_{d=1}^{D}
\left[
m_{k,d} \log m_{k,d}
+ (1 - m_{k,d}) \log (1 - m_{k,d})
\right].
\]

\subsubsection{KL Regularization}

\[
\mathcal{L}_{\text{KL}}
= \bar{m} \log \frac{\bar{m}}{\pi}
+ (1 - \bar{m}) \log \frac{1 - \bar{m}}{1 - \pi},
\quad
\bar{m} = \frac{1}{KD} \sum_{k,d} m_{k,d}.
\]

\subsubsection{Mask Orthogonality Loss}

\[
\mathcal{L}_{\text{mask-sim}}
= \frac{1}{K(K-1)}
\sum_{k_1=1}^{K}
\sum_{\substack{k_2=1 \\ k_2 \neq k_1}}^{K}
\mathbf{M}_{k_1}^\top \mathbf{M}_{k_2}.
\]

\begin{thebibliography}{99}

\bibitem{dubey2024llama}
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, and others.
\newblock The Llama 3 Herd of Models.
\newblock \emph{arXiv preprint arXiv:2407.21783}, 2024.

\bibitem{wadhwa2025circuit}
Somin Wadhwa, Silvio Amir, and Byron C. Wallace.
\newblock Circuit Distillation.
\newblock \emph{arXiv preprint arXiv:2509.25002}, 2025.

\bibitem{wadhwa2024mysteries}
Somin Wadhwa, Silvio Amir, and Byron C. Wallace.
\newblock Investigating mysteries of CoT-augmented distillation.
\newblock In \emph{Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing}, pages 6071--6086, 2024.

\bibitem{elhage2021mathematical}
Nelson Elhage, Neel Nanda, Catherine Olsson, and others.
\newblock A Mathematical Framework for Transformer Circuits.
\newblock \emph{Transformer Circuits Thread}, 2021.

\bibitem{nanda2023attribution}
Neel Nanda.
\newblock Attribution Patching: Activation Patching at Industrial Scale.
\newblock 2023.

\bibitem{kramar2024atp}
János Kramár, Tom Lieberum, Rohin Shah, and Neel Nanda.
\newblock AtP*: An efficient and scalable method for localizing LLM behaviour to components.
\newblock \emph{arXiv preprint arXiv:2403.00745}, 2024.

\bibitem{mueller2025mib}
Aaron Mueller and others.
\newblock MIB: A Mechanistic Interpretability Benchmark.
\newblock \emph{arXiv preprint arXiv:2504.13151}, 2025.

\bibitem{kornblith2019similarity}
Simon Kornblith, Mohammad Norouzi, Honglak Lee, and Geoffrey Hinton.
\newblock Similarity of Neural Network Representations Revisited.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem{williams2025equivalence}
Alex Williams and others.
\newblock An Equivalence Between Representational Similarity Analysis and Centered Kernel Alignment.
\newblock \emph{Cognitive Computational Neuroscience}, 2025.

\end{thebibliography}

\end{document}
